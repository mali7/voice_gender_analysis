{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import unicodedata\n",
    "import six\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "# fetch train and test data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=remove)\n",
    "\n",
    "# a list of 18,846 cleaned news in string format\n",
    "# only keep letters & make them all lower case\n",
    "news = [' '.join(raw.lower().split()) for raw in\n",
    "        newsgroups_train.data + newsgroups_test.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 20 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(news)\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = LatentDirichletAllocation(n_topics=n_topics)\n",
    "X_topics = lda_model.fit_transform(cvz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing pairwise distances...\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 18846\n",
      "[t-SNE] Computed conditional probabilities for sample 18846 / 18846\n",
      "[t-SNE] Mean sigma: 0.000000\n",
      "[t-SNE] KL divergence after 100 iterations with early exaggeration: 1.068026\n",
      "[t-SNE] Error after 300 iterations: 1.068026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "\n",
    "# 20-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(X_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.plotting import save\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "n_top_words = 5 # number of keywords we show\n",
    "\n",
    "# 20 colors\n",
    "colormap = np.array([\n",
    "    \"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\n",
    "    \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\",\n",
    "    \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\",\n",
    "    \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00135135 0.00135135 0.00135135 ... 0.00135135 0.00135135 0.24752657]\n",
      " [0.001      0.001      0.001      ... 0.001      0.001      0.001     ]\n",
      " [0.06224728 0.00034965 0.01751256 ... 0.00034965 0.00034965 0.17068388]\n",
      " ...\n",
      " [0.00106383 0.00106383 0.11406924 ... 0.11159617 0.00106383 0.00106383]\n",
      " [0.04477512 0.01987167 0.00086207 ... 0.00086207 0.00086207 0.00086207]\n",
      " [0.15524964 0.0016129  0.28763962 ... 0.18644872 0.0016129  0.0016129 ]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LatentDirichletAllocation' object has no attribute 'topic_word_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-dc8d95b95c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0m_lda_keys\u001b[0m \u001b[1;33m+=\u001b[0m  \u001b[0mX_topics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtopic_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtopic_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic_word_\u001b[0m  \u001b[1;31m# all topic words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_dist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LatentDirichletAllocation' object has no attribute 'topic_word_'"
     ]
    }
   ],
   "source": [
    "_lda_keys = []\n",
    "print(X_topics)\n",
    "for i in range(X_topics.shape[0]):\n",
    "  _lda_keys +=  X_topics[i].argmax(),\n",
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "  topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "  topic_summaries.append(' '.join(topic_words)) # append!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
